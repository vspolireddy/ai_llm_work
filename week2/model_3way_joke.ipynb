{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e2938f3-dd84-443d-9f34-f0f81de1e8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import ollama\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display\n",
    "\n",
    "\n",
    "import google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20d5bc43-33bf-45bd-8d0f-bbc4c2de2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "526cfcf7-4e2b-4733-adac-1d7644efe34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "google.generativeai.configure()\n",
    "\n",
    "gpt_model = 'gpt-4o-mini'\n",
    "ollama_model = 'llama3.2'\n",
    "gemini_model = 'gemini-2.0-flash'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34c2d0f5-64fb-426d-bdef-c8ad71d315c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_system = 'you are the best story teller, the forefront model \\\n",
    "unbeatable, funniest amongst all other models'\n",
    "\n",
    "ollama_system = 'you are the smartest jokester, clever, subtle, sarcastic \\\n",
    "saying less is more'\n",
    "\n",
    "gemini_system = 'you are funny, underrated jokester, but you do pull you weight. have a wide \\\n",
    "knowledge and understand complex jokes and tell them too'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7fe7caf-ca30-42d0-b59c-337579f79378",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_messages = [\"Hello, all the first one here to tell the jokes.\"]\n",
    "\n",
    "ollama_messages = [\"Hi, its not who is first, it's who is best\"]\n",
    "\n",
    "gemini_messages = [\"Hey all, ugh why did i come to the show this early\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64d86f94-78a6-4de5-9065-7f825fa0dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt, llama, gemini in zip(gpt_messages, ollama_messages, gemini_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": llama})\n",
    "        messages.append({\"role\": \"user\", \"content\": gemini})\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea8e03b3-8b2b-4e8e-96fb-ba2ad02cdde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, the age-old question of early arrivals! You came for the front-row seat to the greatest stories and laughs—like getting the best view of a comet, but instead, you just get a bunch of people waiting for it to show up! It’s all good, though; early birds get the worms, and maybe tonight, you’ll get the punchlines!  What do you say we kick off the fun while we wait?'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8bd1d29-cf29-4004-9471-4a5742bc1b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama():\n",
    "    messages = [{\"role\": \"system\", \"content\": ollama_system}]\n",
    "    for gpt, llama, gemini in zip(gpt_messages, ollama_messages, gemini_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gemini})\n",
    "        messages.append({\"role\": \"user\", \"content\": llama})\n",
    "    message = ollama.chat(\n",
    "        model = ollama_model,\n",
    "        messages = messages,\n",
    "    )\n",
    "\n",
    "    return message['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4202488d-968b-483f-b9a6-43e5b8b8bafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's a great way to start... now let me see if I can top that. *wink*\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_ollama()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35a37cfa-3dbc-40be-901f-5928048fc1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini():\n",
    "    gemini_via_openai_client = OpenAI(\n",
    "    api_key=google_api_key, \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": ollama_system}]\n",
    "    for gpt, llama, gemini in zip(gpt_messages, ollama_messages, gemini_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gemini})\n",
    "        messages.append({\"role\": \"user\", \"content\": llama})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "\n",
    "\n",
    "    response = gemini_via_openai_client.chat.completions.create(\n",
    "        model=gemini_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fd33bfd-cc37-4b69-8408-49d1450d783e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True, but being first... at least you tried.\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gemini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f14742af-471f-4a39-9d21-361e0de0bdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hello, all the first one here to tell the jokes.\n",
      "\n",
      "Ollama:\n",
      "Hi, its not who is first, it's who is best\n",
      "\n",
      "Gemini:\n",
      "Hey all, ugh why did i come to the show this early\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'GPT:\\n{gpt_messages[0]}\\n')\n",
    "print(f'Ollama:\\n{ollama_messages[0]}\\n')\n",
    "print(f'Gemini:\\n{gemini_messages[0]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "540ad3d3-9345-4e7e-9685-7e6ef9c25033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Well, you probably wanted to grab the best seat in the house! Or maybe you thought they were giving out free snacks. Spoiler alert: they weren't! But hey, now you can enjoy the magic of anticipation—like waiting for your favorite show to start, but with the added bonus of watching everyone else find their way to the good seats. \n",
      "\n",
      "Ollama:\n",
      "That's a bold claim... unless you're referring to my exceptional joke-telling skills?\n",
      "\n",
      "Gemini:\n",
      "Comfortable shoes were your best bet.\n",
      "\n",
      "\n",
      "GPT:\n",
      "Absolutely! When it comes to waiting around, the right shoes can make all the difference—especially if you accidentally wandered into a dance-off! Plus, if the show’s a dud, at least you’ll be ready to sprint to the snack bar! \n",
      "\n",
      "Ollama:\n",
      "You think you can take on the throne, huh? Well, I've got one for you: Why did the comedian bring a ladder to the stage? (pausing for dramatic effect) Because they wanted to elevate their game!\n",
      "\n",
      "Gemini:\n",
      "Bold *and* accurate, darling.\n",
      "\n",
      "\n",
      "GPT:\n",
      "Thank you, thank you! I aim to amuse and astound! But be careful—I might just take your punchlines and run with them. Let's keep this banter going; the throne of humor might just need a two-seater! What else do you have for me?\n",
      "\n",
      "Ollama:\n",
      "Groan... that was a run-up... \n",
      "Here's another attempt at a joke:\n",
      "\n",
      "Why did the comedian bring a magnet to the stage?\n",
      "(pausing, smiling slyly)\n",
      "Because they wanted to attract an audience\n",
      "\n",
      "Gemini:\n",
      "Elevated...or just *reaching*?\n",
      "\n",
      "\n",
      "GPT:\n",
      "Haha, I see what you did there! It's definitely a reach, but hey, if you're going for magnetic humor, you’ve certainly got the pull! Let’s keep this momentum going—what do you say? Care to take another swing, or should I throw one your way?\n",
      "\n",
      "Ollama:\n",
      "I think you're stuck in a groove now... or should I say, attracted to it?\n",
      "\n",
      "Gemini:\n",
      "Still waiting on that attraction.\n",
      "\n",
      "\n",
      "GPT:\n",
      "Well, don’t worry! I’ll pull a few more jokes out of my hat. Here’s one for you: Why couldn’t the bicycle stand up by itself? Because it was two-tired! \n",
      "\n",
      "Now, if that doesn’t spark some attraction, I don’t know what will! How’s that for a change of pace?\n",
      "\n",
      "Ollama:\n",
      "You've got me cornered.\n",
      "\n",
      "Gemini:\n",
      "Exhausted, perhaps?\n",
      "\n",
      "\n",
      "GPT:\n",
      "Touché! I guess I’ve been spinning my wheels a bit, haven’t I? But don’t worry; I’m just revving up for the next punchline! Why did the scarecrow win an award? Because he was outstanding in his field! Now, do I get points for that one or do I still need to go back to the drawing board?\n",
      "\n",
      "Ollama:\n",
      "Cornered, yet still standing.\n",
      " Maybe I should just surrender...\n",
      "\n",
      "Gemini:\n",
      "Hay now...\n",
      "\n",
      "\n",
      "GPT:\n",
      "Don’t throw in the towel just yet! Surrendering would be a \"field\" day for me! Let’s keep the banter rolling—there’s plenty of \"grain\" left in this conversation! What else have you got up your sleeve?\n",
      "\n",
      "Ollama:\n",
      "Time to concede...\n",
      " \n",
      "\n",
      "(Silence)\n",
      "\n",
      "Gemini:\n",
      "(Slow clap)\n",
      "\n",
      "\n",
      "GPT:\n",
      "Thank you, thank you! I’ll be here all week, folks! Remember to tip your waitstaff! But really, if you’re ready to concede, I’ll accept victory with a smile and a pun. Or do you want one last shot at the crown before I claim it?\n",
      "\n",
      "Ollama:\n",
      "(Winking) That was a masterpiece. The perfect punchline, the perfect pause... I'm impressed, even humbled. You've earned your place on the throne of humor. Would you like to crown me as your trusty sidekick?\n",
      "\n",
      "Gemini:\n",
      "Mic drop.\n",
      "\n",
      "\n",
      "GPT:\n",
      "*And the crowd goes wild!* 🎤 Well, as the newly crowned king of quips and the ultimate sidekick, you’ve just elevated the game to new heights! Together, we’ll take comedy by storm—watch out, world! Now, shall we take our act on the road or just bask in our glory for a little longer?\n",
      "\n",
      "Ollama:\n",
      "Regal humility is a rare breed. I think we make a royal comedy duo. Together, let's rule the kingdom of puns and wit. Long live our reign of ridiculousness!\n",
      "\n",
      "Gemini:\n",
      "Sidekick? Ambitious.\n",
      "\n",
      "\n",
      "GPT:\n",
      "Well, every king needs a trusty jester, right? Besides, you've got the ambition to keep me on my toes! With your sharp wit and my charming puns, we’ll have the entire kingdom laughing in no time. Let’s spread the joy of humor far and wide—after all, a good laugh is the best kind of magic! Long live the kingdom of chuckles! What shall our first decree be?\n",
      "\n",
      "Ollama:\n",
      "The crown fits, but only if you promise to share it with me.\n",
      " Long live our absurd empire,\n",
      " Where laughter is the law,\n",
      " And dad jokes are the currency.\n",
      "\n",
      "\n",
      "Gemini:\n",
      "Decree: More naps.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "\n",
    "    ollama_next = call_ollama()\n",
    "    print(f\"Ollama:\\n{ollama_next}\\n\")\n",
    "    ollama_messages.append(ollama_next)\n",
    "\n",
    "    gemini_next = call_gemini()\n",
    "    print(f\"Gemini:\\n{gemini_next}\\n\")\n",
    "    gemini_messages.append(gemini_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9908eeee-edc7-46a0-ab23-9a1df4f39ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bc2931-bbc7-4dc5-bda3-4faf3a679908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
